VARIABILITY
Standard deviation has same units as mean, so we use it to measure variability
Var(X) = E[(X-mu)^2] = E[X^2]-E[X]^2; its square root is the standard deviation
Sample variance: S^2 = sum(Xi-X)^2/(n-1)
Sample variance has an associated population distribution;
  its expected value is population variance
E[X]=mu, Var(X)=sigma^2/n, where X is sample
Sample variance estimates the population variance;
  its distribution centered around sigma^2
Standard error of the mean: how variable averages of random samples size N are

DISTRIBUTIONS
Bernoulli distribution: arises as the result of a binary outcome
P(X=x) = p^x(1-p)^(1-x), with variance p(1-p)
Binomial distribution: sum of n trials of a Bernoulli distribution
Normal distribution: bell curve exp(-(x-mu)^2/(2*sigma^2))/sqrt((2*pi*sigma^2))
Standard normal distribution: mu=0, variance and sigma^2 = 1
All normal distributions, when normalized, look exactly the same
  Quantiles: (-1.28, 1.28) are (10th, 90th) percentile
  	     (-1.645, 1.645) are (5th, 95th) percentiles
	     (-1.96, 1.96) are (2.5th, 97.5th) percentiles
	     (-2.33, 2.33) are (1st, 99th) percentiles
Poisson distribution: used to model counts, event-time data
P(X=x;lambda) = lambda^x*exp(-lambda)/x!, mean=variance=lambda
Poisson distributions can also approximate binomials when n large and p small

ASYMPTOTICS
How do statistics behave as the sample size approaches infinity (approximations)
Law of Large Numbers: the average limits to what it is estimating
Estimator is consistent if it converges to what you want to estimate
Sample mean, variance, standard deviation of iid distributions are consistent
  (indeed, they approach the values of a standard normal)
Confidence intervals: the region between which there is a probability of x%
  interval = p+/-(normal quantile)*sqrt(p(1-p)/n) for a normal distribution
  Wald confidence interval = p+/-(1/sqrt(n))
The Wald conf interval is a good quick'n'dirty confidence interval estimator
When n is small (binomial), the Central Limit Theorem may not quite apply yet.
  In this case, use Agresti/Coull confidence interval (X+2)/(n+4)
  This biases the confidence interval toward the mean of 1/2
  Aka this guarantees coverage of 95% confidence interval, but might be too wide
For small values of lambda, don't use an asymptotic interval!
Poisson rates converge to the rates they're estimating, given enough time
Confidence intervals get wider as the coverage increases
